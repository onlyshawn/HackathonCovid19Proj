{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "guitest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riw6Sc6dc_x4",
        "outputId": "c67fe5f1-893f-4112-d5ae-2c0e88ca79d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,676 kB of archives.\n",
            "After this operation, 18.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-minimal amd64 3.8.13-1+bionic1 [762 kB]\n",
            "0% [1 libpython3.8-minimal 2,624 B/762 kB 0%]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H-q81oqdIeE",
        "outputId": "f1a1ab28-c0c4-4cbb-de6a-3e57533300a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0] on linux\n",
            "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
            ">>> \n",
            "KeyboardInterrupt\n",
            ">>> \n",
            "KeyboardInterrupt\n",
            ">>> ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo2q4aewTY6I",
        "outputId": "b18bd207-3aff-4b92-feb3-7a673f3da100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "64\n",
            "Shape of data: (30, 1, 64, 64)\n",
            "[0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 2, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0]\n",
            "[21.  0.  3.  6.]\n"
          ]
        }
      ],
      "source": [
        "import nibabel as nib\n",
        "import torch\n",
        "from model.ResNet import resnet18\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy import ndimage as nd\n",
        "\n",
        "# # create main window\n",
        "# root = tkinter.Tk()\n",
        "# root.title('COVID-19 AI Diagnostic system')\n",
        "\n",
        "# # window config\n",
        "# root.geometry('800x600+100+50')  # width x height + widthoffset + heightoffset\n",
        "# root.configure(bg='white')\n",
        "# root.resizable(False, False)\n",
        "# root.focusmodel()\n",
        "\n",
        "# # logo\n",
        "# img = ImageTk.PhotoImage(Image.open('img.png'))\n",
        "# label = Label(image=img, border=False)\n",
        "# label.place(x=530, y=0)\n",
        "\n",
        "# ct\n",
        "ct_img = None\n",
        "\n",
        "# load model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net = resnet18(pretrained=False, b_RGB=False)\n",
        "net = torch.load('best_ckpt_cnn_33_0.7851.pth',map_location=torch.device(device))#.module.state_dict())\n",
        "# print(net)\n",
        "net = net.cuda()\n",
        "net.eval()\n",
        "ct_img = nib.load(\"study_0256.nii.gz\").get_fdata()\n",
        "\n",
        "\n",
        "# def clear():\n",
        "#     output_valueText.delete(1.0, 'end')\n",
        "\n",
        "# def exit():\n",
        "#     root.destroy()\n",
        "def concatenate(list):\n",
        "    head = list[0]\n",
        "\n",
        "    for i in range(1, len(list)):\n",
        "        head = np.concatenate((head, list[i]), 0)\n",
        "\n",
        "    return np.array(head)\n",
        "\n",
        "    \"\"\"\n",
        "Downsample the image and unify the number of CT slices\n",
        "\"\"\"\n",
        "def resize(img, stand_size, stand_slices):\n",
        "    # img = nd.rotate(img, 90, reshape=False) # unnecessary to rotate images\n",
        "    scale = float(stand_size / img.shape[0])\n",
        "    slices = img.shape[2]\n",
        "    if (stand_slices-slices)==1:\n",
        "        return nd.zoom(input = img[:,:,:slices-1], zoom=(scale, scale, 1), order=1)\n",
        "    # elif (slices-stand_slices)==1:\n",
        "    #     img = nd.zoom(input = img, zoom=(scale, scale, 1), order=1)\n",
        "    #     last = img[:,:,slices-1]\n",
        "    #     img.append(last)\n",
        "    #     return img\n",
        "    return nd.zoom(input = img, zoom=(scale, scale, float(stand_slices/slices)), order=1)\n",
        "\n",
        "\"\"\"\n",
        "    resize image\n",
        "\"\"\"\n",
        "def process_image(img, min_side):\n",
        "    size = img.shape\n",
        "    h, w = size[0], size[1]\n",
        "    # rescale the minside\n",
        "    scale = max(w, h) / float(min_side)\n",
        "    new_w, new_h = int(w/scale), int(h/scale)\n",
        "    resize_img = cv2.resize(img, (new_w, new_h))\n",
        "    # minside * minside\n",
        "    if new_w % 2 != 0 and new_h % 2 == 0:\n",
        "        top, bottom, left, right = (min_side-new_h)/2, (min_side-new_h)/2, (min_side-new_w)/2 + 1, (min_side-new_w)/2\n",
        "    elif new_h % 2 != 0 and new_w % 2 == 0:\n",
        "        top, bottom, left, right = (min_side-new_h)/2 + 1, (min_side-new_h)/2, (min_side-new_w)/2, (min_side-new_w)/2\n",
        "    elif new_h % 2 == 0 and new_w % 2 == 0:\n",
        "        top, bottom, left, right = (min_side-new_h)/2, (min_side-new_h)/2, (min_side-new_w)/2, (min_side-new_w)/2\n",
        "    else:\n",
        "        top, bottom, left, right = (min_side-new_h)/2 + 1, (min_side-new_h)/2, (min_side-new_w)/2 + 1, (min_side-new_w)/2\n",
        "    pad_img = cv2.copyMakeBorder(resize_img, int(top), int(bottom), int(left), int(right), cv2.BORDER_CONSTANT, value=[0,0,0]) #\n",
        "    return pad_img\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Use model to diagnose\n",
        "\"\"\"\n",
        "def diagnose():\n",
        "    global ct_img\n",
        "    ct_img = resize(ct_img,64,30)\n",
        "    # clear()\n",
        "    slices = ct_img.shape[2]\n",
        "    diag = np.zeros(4)\n",
        "\n",
        "            # images = [[]]\n",
        "            # img_list = []\n",
        "            # for id in range(tmp.shape[2]):\n",
        "            #     # image size control\n",
        "            #     tmp_img = process_image(tmp[:, :, id], 64)\n",
        "            #     img_list.append(tmp_img)\n",
        "            # images[i].append(np.array(img_list))\n",
        "\n",
        "    img_list = []\n",
        "    images = [[]]\n",
        "    for i in range(30):\n",
        "        img_list.append(process_image(ct_img[i],64))\n",
        "    images[0].append(np.array(img_list))#.swapaxes(1,2))\n",
        "\n",
        "    images[0] = concatenate(images[0])\n",
        "    np.random.shuffle(images[0])\n",
        "    print(len(images[0][1]))\n",
        "\n",
        "\n",
        "    img_set = images[0][:,np.newaxis].astype(np.float32)\n",
        "    print(\"Shape of data: \" + str(img_set.shape))\n",
        "    loader = torch.utils.data.DataLoader(img_set, batch_size=4)\n",
        "    output = []\n",
        "    for i, (img_data) in enumerate(loader):\n",
        "        img_data = img_data.cuda()\n",
        "        res = net(img_data)\n",
        "\n",
        "        output.extend(np.argmax(res.detach().cpu().numpy(), 1))\n",
        "        # all_preds = \n",
        "\n",
        "    # output = torch.tensor(np.array(output))\n",
        "    print(output)\n",
        "    # _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(output)\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] == 0:\n",
        "            diag[0]+=1\n",
        "        elif preds[i] == 1:\n",
        "            diag[1]+=1\n",
        "        elif preds[i] == 2:\n",
        "            diag[2]+=1\n",
        "        elif preds[i] == 3:\n",
        "            diag[3]+=1\n",
        "    print(diag)\n",
        "\n",
        "\n",
        "diagnose()"
      ]
    }
  ]
}